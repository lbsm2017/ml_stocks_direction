{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VaR & CVaR based on Energy Factors - Montecarlo approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.svm import SVC\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import time\n",
    "import cvxpy as cp\n",
    "from scipy.optimize import minimize\n",
    "import yfinance as yf\n",
    "import warnings \n",
    "import tqdm\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##storico totale\n",
    "start_date  = '2008-01-01'\n",
    "end_date    = '2023-06-10'\n",
    "timeframe   = 'M'\n",
    "rolling_periods = 3\n",
    "std_mode    = 'max' #median , max , iqr, q90\n",
    "\n",
    "stock_symb  = 'TSLA'\n",
    "fact_symbs  = 'NG=F, CL=F, MTF=F, HO=F,ICLN, IXC, URA'\n",
    "cv_folds    = 10\n",
    "\n",
    "num_years   = 20\n",
    "num_runs    = 2500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_factors = yf.download(fact_symbs,start=start_date, end=end_date)['Adj Close']\n",
    "energy_factors = np.log1p(energy_factors.pct_change())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = yf.download(stock_symb,start=start_date, end=end_date)['Adj Close']\n",
    "stock_last_prince = float(stock[-1])\n",
    "stock = np.log1p(stock.pct_change())\n",
    "stock.name = stock_symb\n",
    "stock_last_prince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = pd.concat([energy_factors, stock], axis=1).dropna()\n",
    "# data['SPY'] = data['SPY'].shift(-1)\n",
    "plt.figure(figsize=(20,7))\n",
    "sns.lineplot(daily_data.cumsum())\n",
    "# data.cumsum().plot()\n",
    "daily_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_options():\n",
    "    '''create standard options dictionary to be used as input to regression functions'''\n",
    "    options = dict()\n",
    "    options['time_period'] = 'all'\n",
    "    options['date'] = 'Date'\n",
    "    options['return_model'] = False\n",
    "    options['print_loadings'] = True\n",
    "    return options\n",
    "\n",
    "def create_options_lasso():\n",
    "    options = create_options()\n",
    "    options['lambda_hat'] = .5\n",
    "    return options\n",
    "\n",
    "def create_options_cv_lasso():\n",
    "    options = create_options()\n",
    "    options['max_lambda_hat'] = 1\n",
    "    options['n_lambda_hat'] = 250\n",
    "    options['random_state'] = 7777\n",
    "    options['n_folds'] = 10\n",
    "    return options\n",
    "\n",
    "def create_options_cv_ridge():\n",
    "    options = create_options()\n",
    "    options['max_lambda'] = 1\n",
    "    options['n_lambda'] = 250\n",
    "    options['random_state'] = 7777\n",
    "    options['n_folds'] = 10\n",
    "    return options\n",
    "\n",
    "def create_options_cv_elastic_net():\n",
    "    options = create_options()\n",
    "    options['max_lambda_hat'] = 1\n",
    "    options['max_l1_ratio'] = .99\n",
    "    options['n_lambda_hat'] = 250\n",
    "    options['n_l1_ratio'] = 20\n",
    "    options['random_state'] = 7777\n",
    "    options['n_folds'] = 10\n",
    "    return options\n",
    "\n",
    "def create_options_best_subset():\n",
    "    '''create standard options dictionary to be used as input to regression functions'''\n",
    "    options = create_options()\n",
    "    options['return_model'] = False\n",
    "    options['print_loadings'] = True\n",
    "    options['max_vars'] = 3\n",
    "    return options\n",
    "\n",
    "def num_to_month(month):\n",
    "    #num to month returns the name of the month, input is an integer\n",
    "    if (month==1):\n",
    "        return 'January'\n",
    "    if (month==2):\n",
    "        return 'Febuary'\n",
    "    if (month==3):\n",
    "        return 'March'\n",
    "    if (month==4):\n",
    "        return 'April'\n",
    "    if (month==5):\n",
    "        return 'May'\n",
    "    if (month==6):\n",
    "        return 'June'\n",
    "    if (month==7):\n",
    "        return 'July'\n",
    "    if (month==8):\n",
    "        return 'August'\n",
    "    if (month==9):\n",
    "        return 'September'\n",
    "    if (month==10):\n",
    "        return 'October'\n",
    "    if (month==11):\n",
    "        return 'November'\n",
    "    if (month==12):\n",
    "        return 'December'\n",
    "\n",
    "def display_factor_loadings(intercept, coefs, factorNames, options):\n",
    "    '''display_factor_loadings takes an intercept, coefs, factorNames and options dict, and prints the factor loadings in a readable way\n",
    "    INPUTS:\n",
    "        intercept: float, intercept value\n",
    "        coefs: np array, coeficients from pandas df\n",
    "        factorNames: list, names of the factors\n",
    "        options: dict, should contain at least one key, nameOfReg\n",
    "            nameOfReg: string, name for the regression\n",
    "    Outputs:\n",
    "        output is printed\n",
    "    '''\n",
    "    loadings = np.insert(coefs, 0, intercept)\n",
    "    if('name_of_reg' not in options.keys()):\n",
    "        name = 'No Name'\n",
    "    else:\n",
    "        name = options['name_of_reg']\n",
    "    out = pd.DataFrame(loadings, columns=[name])\n",
    "    out = out.transpose()\n",
    "    fullNames = ['Intercept'] + factorNames\n",
    "    out.columns = fullNames\n",
    "    print(out)\n",
    "\n",
    "def print_timeperiod(data, dependentVar, options):\n",
    "    '''print_timeperiod takes a a dependent varaible and a options dictionary, prints out the time period\n",
    "    INPUTS:\n",
    "        data: pandas df, df with the data\n",
    "        dependentVar: string, name of dependent variable\n",
    "        options: dictionary, should constain at least two elements, timeperiod, and date\n",
    "            timeperiod: string, if == all, means use entire dataframe, otherwise filter the df on this value\n",
    "            date: name of datecol\n",
    "    OUTPUTS:\n",
    "        printed stuff\n",
    "    '''\n",
    "    print ('Dependent Variable is ' + dependentVar)\n",
    "    if(options['time_period'] == 'all'):\n",
    "        sortedValues = data.sort_values(options['date'])[options['date']].reset_index(drop=True)\n",
    "        n = sortedValues.shape[0]\n",
    "        beginDate = sortedValues[0]\n",
    "        endDate = sortedValues[n-1]\n",
    "        print ('Time period is between ' + num_to_month(beginDate.month) +  ' ' + str(beginDate.year) + ' to ' + num_to_month(endDate.month) +  ' ' + str(endDate.year) + ' inclusive   ')        \n",
    "    else:\n",
    "        print ('Time period is ' + options['timeperiod'])\n",
    "\n",
    "def linear_regression(data, dependentVar, factorNames, options):\n",
    "    '''linear_regression takes in a dataset and returns the factor loadings using least squares regression\n",
    "    INPUTS:\n",
    "        data: pandas df, data matrix, should constain the date column and all of the factorNames columns\n",
    "        dependentVar: string, name of dependent variable\n",
    "        factorNames: list, elements should be strings, names of the independent variables\n",
    "        options: dictionary, should constain at least two elements, timeperiod, and date\n",
    "            timeperiod: string, if == all, means use entire dataframe, otherwise filter the df on this value\n",
    "            date: name of datecol\n",
    "            returnModel: boolean, if true, returns model\n",
    "    Outputs:\n",
    "        reg: regression object from sikitlearn\n",
    "        also prints what was desired\n",
    "    '''\n",
    "    #first filter down to the time period\n",
    "    if(options['time_period'] == 'all'):\n",
    "        newData = data.copy()\n",
    "    else:\n",
    "        newData = data.copy()\n",
    "        newData = newData.query(options['time_period'])\n",
    "\n",
    "    #perform linear regression\n",
    "    linReg = LinearRegression(fit_intercept=True)\n",
    "    linReg.fit(newData[factorNames], newData[dependentVar])\n",
    "    \n",
    "    if (options['print_loadings'] == True):\n",
    "        #Now print the results\n",
    "        print_timeperiod(newData, dependentVar, options)\n",
    "        # Now print the factor loadings\n",
    "        display_factor_loadings(linReg.intercept_, linReg.coef_, factorNames, options)\n",
    "\n",
    "    if(options['return_model']):\n",
    "        return linReg\n",
    "      \n",
    "def lasso_regression(data, dependentVar, factorNames, options):\n",
    "    '''lasso_regression takes in a dataset and returns the factor loadings using lasso regression\n",
    "    INPUTS:\n",
    "        data: pandas df, data matrix, should constain the date column and all of the factorNames columns\n",
    "        dependentVar: string, name of dependent variable\n",
    "        factorNames: list, elements should be strings, names of the independent variables\n",
    "        options: dictionary, should constain at least two elements, timeperiod, and date\n",
    "            timeperiod: string, if == all, means use entire dataframe, otherwise filter the df on this value\n",
    "            printLoadings: boolean, if true, prints the coeficients\n",
    "\n",
    "            date: name of datecol\n",
    "            returnModel: boolean, if true, returns model\n",
    "            alpha: float, alpha value for LASSO regression\n",
    "            NOTE: SKLearn calles Lambda Alpha.  Also, it uses a scaled version of LASSO argument, so here I scale when converting lambda to alpha\n",
    "    Outputs:\n",
    "        reg: regression object from sikitlearn\n",
    "        also prints what was desired\n",
    "    '''\n",
    "    if('lambda_hat' not in options.keys()):\n",
    "        print ('lambda_hat not specified in options')\n",
    "        return\n",
    "\n",
    "    #first filter down to the time period\n",
    "    if(options['time_period'] == 'all'):\n",
    "        newData = data.copy()\n",
    "    else:\n",
    "        newData = data.copy()\n",
    "        newData = newData.query(options['time_period'])\n",
    "\n",
    "    #perform linear regression\n",
    "    lassoReg = Lasso(alpha=options['lambda_hat'], fit_intercept=True)\n",
    "    lassoReg.fit(newData[factorNames], newData[dependentVar])\n",
    "    \n",
    "    if (options['print_loadings'] == True):\n",
    "        #Now print the results\n",
    "        print_timeperiod(newData, dependentVar, options)\n",
    "        print('lambda_hat = ' + str(options['lambda_hat']))\n",
    "\n",
    "        #Now print the factor loadings\n",
    "        display_factor_loadings(lassoReg.intercept_, lassoReg.coef_, factorNames, options)\n",
    "        \n",
    "def cross_validated_lasso_regression(data, dependentVar, factorNames, options):\n",
    "    '''cross_validated_lasso_regression takes in a dataset and returns the factor loadings using lasso regression and cross validating the choice of lambda\n",
    "    INPUTS:\n",
    "        data: pandas df, data matrix, should constain the date column and all of the factorNames columns\n",
    "        dependentVar: string, name of dependent variable\n",
    "        factorNames: list, elements should be strings, names of the independent variables\n",
    "        options: dictionary, should constain at least two elements, timeperiod, and date\n",
    "            timeperiod: string, if == all, means use entire dataframe, otherwise filter the df on this value\n",
    "            date: name of datecol\n",
    "            returnModel: boolean, if true, returns model\n",
    "            printLoadings: boolean, if true, prints the coeficients\n",
    "\n",
    "            maxLambda: float, max lambda value passed\n",
    "            nLambdas: int, number of lambda values to try\n",
    "            randomState: integer, sets random state seed\n",
    "            nFolds: number of folds\n",
    "            NOTE: SKLearn calles Lambda Alpha.  Also, it uses a scaled version of LASSO argument, so here I scale when converting lambda to alpha\n",
    "    Outputs:\n",
    "        reg: regression object from sikitlearn\n",
    "        also prints what was desired\n",
    "    '''\n",
    "    #Test timeperiod\n",
    "    if(options['time_period'] == 'all'):\n",
    "        newData = data.copy()\n",
    "    else:\n",
    "        newData = data.copy()\n",
    "        newData = newData.query(options['time_period'])\n",
    "\n",
    "    #Do CV Lasso\n",
    "    alphas = np.logspace(-12, np.log(options['max_lambda_hat']), base=np.exp(1), num=options['n_lambda_hat'])\n",
    "    #alphas = np.linspace(1e-12, alphaMax, options['nAlphas'])\n",
    "    if(options['random_state'] == 'none'):\n",
    "        lassoTest = Lasso(fit_intercept=True)\n",
    "    else:\n",
    "        lassoTest = Lasso(random_state = options['random_state'], fit_intercept=True)\n",
    "\n",
    "    tuned_parameters = [{'alpha': alphas}]\n",
    "\n",
    "    clf = GridSearchCV(lassoTest, tuned_parameters, cv=options['n_folds'], refit=True)\n",
    "    clf.fit(newData[factorNames],newData[dependentVar])\n",
    "    lassoBest = clf.best_estimator_\n",
    "    alphaBest = clf.best_params_['alpha']\n",
    "\n",
    "    if (options['print_loadings'] == True):\n",
    "        #Now print the results\n",
    "        print_timeperiod(newData, dependentVar, options)\n",
    "        print('Best lambda_hat = ' + str(alphaBest))\n",
    "        #Now print the factor loadings\n",
    "        display_factor_loadings(lassoBest.intercept_, lassoBest.coef_, factorNames, options)\n",
    "\n",
    "    if(options['return_model']):\n",
    "        return lassoBest\n",
    "    \n",
    "def cross_validated_ridge_regression(data, dependentVar, factorNames, options):\n",
    "    '''cross_validated_ridge_regression takes in a dataset and returns the factor loadings using ridge regression and choosing lambda via ridge regression\n",
    "    INPUTS:\n",
    "        data: pandas df, data matrix, should constain the date column and all of the factorNames columns\n",
    "        dependentVar: string, name of dependent variable\n",
    "        factorNames: list, elements should be strings, names of the independent variables\n",
    "        options: dictionary, should constain at least two elements, timeperiod, and date\n",
    "            timeperiod: string, if == all, means use entire dataframe, otherwise filter the df on this value\n",
    "            date: name of datecol\n",
    "            returnModel: boolean, if true, returns model\n",
    "            printLoadings: boolean, if true, prints the coeficients\n",
    "\n",
    "            maxLambda: float, max lambda value passed\n",
    "            nLambdas: int, number of lambda values to try\n",
    "            randomState: integer, sets random state seed\n",
    "            nFolds: number of folds\n",
    "            NOTE: SKLearn calles Lambda Alpha.  So I change Lambda -> Alpha in the following code\n",
    "    Outputs:\n",
    "        reg: regression object from sikitlearn\n",
    "        also prints what was desired\n",
    "    '''\n",
    "    #Test timeperiod\n",
    "    if(options['time_period'] == 'all'):\n",
    "        newData = data.copy()\n",
    "    else:\n",
    "        newData = data.copy()\n",
    "        newData = newData.query(options['time_period'])\n",
    "\n",
    "    #Do CV Lasso\n",
    "    alphaMax = options['max_lambda']\n",
    "    alphas = np.logspace(-12, np.log(alphaMax), num=options['n_lambda'], base=np.exp(1))\n",
    "    if(options['randomState'] == 'none'):\n",
    "        ridgeTest = Ridge(fit_intercept=True)\n",
    "    else:\n",
    "        ridgeTest = Ridge(random_state = options['randomState'], fit_intercept=True)\n",
    "\n",
    "    tuned_parameters = [{'alpha': alphas}]\n",
    "\n",
    "    clf = GridSearchCV(ridgeTest, tuned_parameters, cv=options['n_folds'], refit=True)\n",
    "    clf.fit(newData[factorNames],newData[dependentVar])\n",
    "    ridgeBest = clf.best_estimator_\n",
    "    alphaBest = clf.best_params_['alpha']\n",
    "\n",
    "    if (options['print_loadings'] == True):\n",
    "        #Now print the results\n",
    "        print_timeperiod(newData, dependentVar, options)\n",
    "        print('Best Lambda = ' + str(alphaBest))\n",
    "        #Now print the factor loadings\n",
    "        display_factor_loadings(ridgeBest.intercept_, ridgeBest.coef_, factorNames, options)\n",
    "\n",
    "    if(options['return_model']):\n",
    "        return ridgeBest\n",
    "\n",
    "def cross_validated_elastic_net_regression(data, dependentVar, factorNames, options):\n",
    "    '''cross_validated_elastic_net_regression takes in a dataset and returns the factor loadings using elastic net, also chooses alpha and l1 ratio via cross validation\n",
    "    INPUTS:\n",
    "        data: pandas df, data matrix, should constain the date column and all of the factorNames columns\n",
    "        dependentVar: string, name of dependent variable\n",
    "        factorNames: list, elements should be strings, names of the independent variables\n",
    "        options: dictionary, should constain at least two elements, timeperiod, and date\n",
    "            timeperiod: string, if == all, means use entire dataframe, otherwise filter the df on this value\n",
    "            date: name of datecol\n",
    "            returnModel: boolean, if true, returns model\n",
    "            printLoadings: boolean, if true, prints the coeficients\n",
    "\n",
    "            maxLambda: float, max lambda value passed\n",
    "            nLambdas: int, number of lambda values to try\n",
    "            maxL1Ratio: float\n",
    "            randomState: integer, sets random state seed\n",
    "            nFolds: number of folds\n",
    "            NOTE: SKLearn calles Lambda Alpha.  So I change Lambda -> Alpha in the following code\n",
    "    Outputs:\n",
    "        reg: regression object from sikitlearn\n",
    "        also prints what was desired\n",
    "    '''\n",
    "    #Test timeperiod\n",
    "    if(options['time_period'] == 'all'):\n",
    "        newData = data.copy()\n",
    "    else:\n",
    "        newData = data.copy()\n",
    "        newData = newData.query(options['time_period'])\n",
    "\n",
    "    #Do CV Lasso\n",
    "    alphaMax = options['max_lambda_hat']\n",
    "    alphas = np.logspace(-12, np.log(alphaMax), num=options['n_lambda_hat'])\n",
    "    l1RatioMax = options['max_l1_ratio']\n",
    "    l1Ratios = np.linspace(1e-6, l1RatioMax, options['n_l1_ratio'])\n",
    "    if(options['random_state'] == 'none'):\n",
    "        elasticNetTest = ElasticNet(fit_intercept=True)\n",
    "    else:\n",
    "        elasticNetTest = ElasticNet(random_state = options['random_state'], fit_intercept=True)\n",
    "\n",
    "    tuned_parameters = [{'alpha': alphas, 'l1_ratio': l1Ratios}]\n",
    "\n",
    "    clf = GridSearchCV(elasticNetTest, tuned_parameters, cv=options['n_folds'], refit=True)\n",
    "    clf.fit(newData[factorNames],newData[dependentVar])\n",
    "    elasticNetBest = clf.best_estimator_\n",
    "    alphaBest = clf.best_params_['alpha']\n",
    "    l1RatioBest = clf.best_params_['l1_ratio']\n",
    "\n",
    "    if (options['print_loadings'] == True):\n",
    "        #Now print the results\n",
    "        print_timeperiod(newData, dependentVar, options)\n",
    "        print('Best lambda_hat = ' + str(alphaBest))\n",
    "        print('Best l1 ratio = ' + str(l1RatioBest))\n",
    "        #Now print the factor loadings\n",
    "        display_factor_loadings(elasticNetBest.intercept_, elasticNetBest.coef_, factorNames, options)\n",
    "\n",
    "    if(options['return_model']):\n",
    "        return elasticNetBest\n",
    "\n",
    "def best_subset(x,y,l_0):\n",
    "    # Mixed Integer Programming in feature selection\n",
    "    M = 1000\n",
    "    n_factor = x.shape[1]\n",
    "    z = cp.Variable(n_factor, boolean=True)\n",
    "    beta = cp.Variable(n_factor)\n",
    "    alpha = cp.Variable(1)\n",
    "\n",
    "    def MIP_obj(x,y,b,a):\n",
    "        return cp.norm(y-cp.matmul(x,b)-a,2)\n",
    "\n",
    "    best_subset_prob = cp.Problem(cp.Minimize(MIP_obj(x, y, beta, alpha)), \n",
    "                             [cp.sum(z)<=l_0, beta+M*z>=0, M*z>=beta])\n",
    "    best_subset_prob.solve(solver='ECOS_BB')\n",
    "    return alpha.value, beta.value\n",
    "\n",
    "def best_subset_regression(data, dependentVar, factorNames, options):\n",
    "    '''best_subset_regression takes in a dataset and returns the factor loadings using best subset regression\n",
    "    INPUTS:\n",
    "        data: pandas df, data matrix, should constain the date column and all of the factorNames columns\n",
    "        dependentVar: string, name of dependent variable\n",
    "        factorNames: list, elements should be strings, names of the independent variables\n",
    "        options: dictionary, should constain at least two elements, timeperiod, and date\n",
    "            timeperiod: string, if == all, means use entire dataframe, otherwise filter the df on this value\n",
    "            date: name of datecol\n",
    "            returnModel: boolean, if true, returns model\n",
    "            maxVars: int, maximum number of factors that can have a non zero loading in the resulting regression\n",
    "            printLoadings: boolean, if true, prints the coeficients\n",
    "    Outputs:\n",
    "        reg: regression object from sikitlearn\n",
    "        also prints what was desired\n",
    "    '''\n",
    "    #Check dictionary for maxVars option\n",
    "    if('max_vars' not in options.keys()):\n",
    "        print ('max_vars not specified in options')\n",
    "        return\n",
    "\n",
    "    if(options['time_period'] == 'all'):\n",
    "        newData = data.copy()\n",
    "    else:\n",
    "        newData = data.copy()\n",
    "        newData = newData.query(options['time_period'])\n",
    "\n",
    "    #perform linear regression\n",
    "    alpha, beta = best_subset(data[factorNames].values, data[dependentVar].values, options['max_vars'])\n",
    "    #round beta values to zero\n",
    "    beta[np.abs(beta) <= 1e-7] = 0.0\n",
    "    \n",
    "    if (options['print_loadings'] == True):\n",
    "        #Now print the results\n",
    "        print_timeperiod(newData, dependentVar, options)\n",
    "        print('Max Number of Non-Zero Variables is ' + str(options['max_vars']))\n",
    "\n",
    "        #Now print the factor loadings\n",
    "        display_factor_loadings(alpha, beta, factorNames, options)\n",
    "\n",
    "    if(options['return_model']):\n",
    "        out = LinearRegression()\n",
    "        out.intercept_ = alpha[0]\n",
    "        out.coef_ = beta\n",
    "        return out\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_data = daily_data.copy()\n",
    "resampled_data.dropna(how='any', inplace=True)\n",
    "\n",
    "if timeframe == 'W':\n",
    "    resampled_data = resampled_data.resample('W').sum()\n",
    "elif timeframe == 'M':\n",
    "    resampled_data = resampled_data.resample('M').sum()\n",
    "elif timeframe == 'Q':\n",
    "    resampled_data = resampled_data.resample('Q').sum()\n",
    "\n",
    "resampled_data.dropna(how='any', inplace=True)\n",
    "\n",
    "factors = resampled_data.drop(stock_symb, axis=1).columns.tolist()\n",
    "resampled_data.reset_index(inplace=True)\n",
    "resampled_data.rename(columns={'index': 'Date'}, inplace=True)\n",
    "\n",
    "# Continue with the rest of your code using the resampled_data\n",
    "resampled_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = create_options()\n",
    "options['name_of_reg'] = 'OLS full data'\n",
    "options['return_model'] = True\n",
    "ols_model_train = linear_regression(resampled_data, stock_symb, factors, options)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penalized Regressions (Lasso , Elastic Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = create_options_cv_lasso()\n",
    "options['name_of_reg'] = 'CV Lasso'\n",
    "options['max_lambda_hat'] = .01 #This specifies the maximum Alpha value tested by cross validation, minimum value is zero\n",
    "options['return_model'] = True\n",
    "options['n_folds'] = cv_folds \n",
    "lasso_model_train = cross_validated_lasso_regression(resampled_data, stock_symb, factors, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = create_options_cv_elastic_net()\n",
    "options['name_of_reg'] = 'CV Elastic Net'\n",
    "options['max_lambda_hat'] = .01\n",
    "options['return_model'] = True\n",
    "options['n_folds'] = cv_folds\n",
    "en_model_train = cross_validated_elastic_net_regression(resampled_data, stock_symb, factors, options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = en_model_train.intercept_\n",
    "betas = en_model_train.coef_\n",
    "betas = betas.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIF Collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the independent variables set\n",
    "X = resampled_data[factors]\n",
    "\n",
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "\n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "\t\t\t\t\t\tfor i in range(len(X.columns))]\n",
    "\n",
    "print(vif_data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset for Montecarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the historical data\n",
    "df_factors = resampled_data.drop(['Date',stock_symb], axis=1).dropna()\n",
    "\n",
    "# Compute mean returns for each factor\n",
    "mean_returns = df_factors.mean()\n",
    "\n",
    "# Compute the rolling volatility\n",
    "rolling_volatility = df_factors.rolling(window=rolling_periods).std()\n",
    "\n",
    "# Compute the maximum rolling volatility over the last 15 years for each factor\n",
    "if std_mode == 'median':\n",
    "    _rolling_volatility = rolling_volatility.median()\n",
    "elif std_mode == 'max':\n",
    "    _rolling_volatility = rolling_volatility.max()\n",
    "elif std_mode == 'iqr':\n",
    "    _rolling_volatility = rolling_volatility.quantile(0.75) - rolling_volatility.quantile(0.25)\n",
    "elif std_mode == 'q90':\n",
    "    _rolling_volatility = rolling_volatility.quantile(0.90) \n",
    "\n",
    "# Store the maximum rolling volatility for each factor in sigmas_list\n",
    "sigmas_list = _rolling_volatility.tolist()\n",
    "\n",
    "mean_returns_list = mean_returns.tolist()\n",
    "\n",
    "print(\"Mean Returns:\", mean_returns_list)\n",
    "print(\"Rolling Volatility:\", sigmas_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Montecarlo simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if timeframe=='D':\n",
    "    n_steps = num_years * 252\n",
    "elif timeframe=='W':\n",
    "    n_steps = num_years * 52\n",
    "elif timeframe=='M':\n",
    "    n_steps = num_years * 12\n",
    "elif timeframe=='Q':\n",
    "    n_steps = num_years * 4\n",
    "\n",
    "\n",
    "initial_stock_price = float(stock_last_prince)  \n",
    "np.random.seed(42)\n",
    "\n",
    "#Brownian motion\n",
    "brownian_motion_paths = []\n",
    "for i in range(len(mean_returns_list)):\n",
    "    brownian_motion_path = np.random.normal(mean_returns_list[i], sigmas_list[i], size=(num_runs, n_steps))\n",
    "    brownian_motion_paths.append(brownian_motion_path)\n",
    "\n",
    "# Generate future stock prices\n",
    "future_stock_prices = np.zeros((num_runs, n_steps))\n",
    "future_stock_prices[:, 0] = initial_stock_price  \n",
    "\n",
    "for i in tqdm.tqdm(range(1, n_steps), desc='Generating future stock prices'):\n",
    "    for j in range(num_runs):\n",
    "        energy_factor_returns = np.dot([brownian_motion_paths[k][j, i-1] for k in range(len(mean_returns_list))], betas)\n",
    "        future_stock_prices[j, i] = future_stock_prices[j, i-1] * (1 + energy_factor_returns)\n",
    "\n",
    "\n",
    "# Compute stock returns\n",
    "stock_returns = np.diff(future_stock_prices, axis=1) / future_stock_prices[:, :-1]\n",
    "\n",
    "# Calculate VaR and CVaR \n",
    "confidence_level = 0.95\n",
    "var = np.percentile(stock_returns, (1 - confidence_level) * 100)\n",
    "cvar = np.mean(stock_returns[stock_returns <= var])\n",
    "\n",
    "print(f'{stock_symb}: next {num_years} years | {num_runs} iterations')\n",
    "print(f'Energy Factors: {fact_symbs}')\n",
    "print(\"VaR:\", \"{:.2f}%\".format(var * 100))\n",
    "print(\"CVaR:\", \"{:.2f}%\".format(cvar * 100))\n",
    "\n",
    "\n",
    "# Plot stock pathways\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(num_runs):\n",
    "    plt.plot(range(n_steps), future_stock_prices[i], linewidth=0.8, alpha=0.4)\n",
    "\n",
    "plt.xlabel(f'Periods: {timeframe}')\n",
    "plt.ylabel('$ Price')\n",
    "plt.title(f'{stock_symb} Pathways - Monte Carlo Simulation')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VaR and CVaR Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of returns\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(stock_returns.flatten(), bins=50, density=True, edgecolor='k', alpha=0.5)\n",
    "plt.xlabel(f'{stock_symb} Returns')\n",
    "plt.ylabel('Density')\n",
    "plt.title(f'Distribution of {stock_symb} Returns | Timeframe {timeframe} | {num_years} years')\n",
    "\n",
    "# Format VaR and CVaR as percentages with two decimal points\n",
    "var_formatted = \"{:.2f}%\".format(var * 100)\n",
    "cvar_formatted = \"{:.2f}%\".format(cvar * 100)\n",
    "\n",
    "# Plot vertical lines for VaR and CVaR with formatted values in the legend\n",
    "plt.axvline(var, color='blue', linestyle='dotted', linewidth=2, label=f'VaR ({var_formatted})')\n",
    "plt.axvline(cvar, color='red', linestyle='--', linewidth=2, label=f'CVaR ({cvar_formatted})')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
